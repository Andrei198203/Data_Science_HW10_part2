{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUmlm5gl3WeYEVnrgeJP+Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrei198203/Data_Science_HW10_part2/blob/main/HW10_part2_Data_Science.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nb6eAir4nGWS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img, ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading data\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "2-dxXmjqnV0i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data conversion and normalisation\n",
        "train_images = tf.reshape(train_images, (train_images.shape[0], 28, 28, 1)).numpy().astype('float32') / 255\n",
        "test_images = tf.reshape(test_images, (test_images.shape[0], 28, 28, 1)).numpy().astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "tuv9u0Fanbtq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert images up to 3 channels and resize\n",
        "train_images_rgb = np.asarray([img_to_array(array_to_img(image).convert('RGB')) for image in train_images])\n",
        "test_images_rgb = np.asarray([img_to_array(array_to_img(image).convert('RGB')) for image in test_images])\n",
        "\n",
        "train_images_resized = tf.image.resize(train_images_rgb, (48, 48))\n",
        "test_images_resized = tf.image.resize(test_images_rgb, (48, 48))"
      ],
      "metadata": {
        "id": "pADhZKCTpAVu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img"
      ],
      "metadata": {
        "id": "Hb3kAnSrqNaE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-treatment in accordance with VGG16\n",
        "train_images_preprocessed = preprocess_input(train_images_resized)\n",
        "test_images_preprocessed = preprocess_input(test_images_resized)"
      ],
      "metadata": {
        "id": "QHiiCgOqqBDD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the pre-trained VGG16 model without the top fully bonded layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))"
      ],
      "metadata": {
        "id": "p3KLPu0KpIDB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding top layers\n",
        "model = models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "TniEB_-9pgCI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freezing scales model VGG16\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "sK3ypXiRpmVJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model compilation\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-QjWppIUpp1S"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "history = model.fit(train_images_preprocessed, train_labels, epochs=5, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2NX0sgBpuH-",
        "outputId": "33eff144-6ff0-4ac4-f961-6b1f32d23739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "750/750 [==============================] - 1433s 2s/step - loss: 1.3310 - accuracy: 0.7348 - val_loss: 0.4917 - val_accuracy: 0.8211\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 1379s 2s/step - loss: 0.5418 - accuracy: 0.8102 - val_loss: 0.4320 - val_accuracy: 0.8441\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 1424s 2s/step - loss: 0.4809 - accuracy: 0.8260 - val_loss: 0.4278 - val_accuracy: 0.8472\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 1442s 2s/step - loss: 0.4496 - accuracy: 0.8365 - val_loss: 0.4153 - val_accuracy: 0.8512\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.4282 - accuracy: 0.8431"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating accuracy on test data\n",
        "test_loss, test_acc = model.evaluate(test_images_preprocessed, test_labels)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7yBk64Krpq7",
        "outputId": "4463c073-ff2a-4ee4-bb39-a73b028faf9d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 232s 741ms/step - loss: 0.4249 - accuracy: 0.8515\n",
            "Test accuracy: 0.8514999747276306\n"
          ]
        }
      ]
    }
  ]
}